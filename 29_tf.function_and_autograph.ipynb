{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 1, graphs were unavoidable (as were the complexities that came with\n",
    "them): they were a central part of TensorFlow’s API. In TensorFlow 2, they are still \n",
    "there, but not as central, and much (much!) simpler to use. \n",
    "\n",
    "To demonstrate this, let’s\n",
    "start with a trivial function that just computes the cube of its input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cube = tf.function(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7fabd73b25c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Under the hood, tf.function() analyzed the computations performed by the cube()\n",
    "function and generated an equivalent computation graph!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively, we could have used\n",
    "tf.function as a decorator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Python function is still available via the TF Function’s python_function\n",
    "attribute, in case you ever need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you write a custom loss function, a custom metric, a custom layer or\n",
    "any other custom function, and you use it in a Keras model (as we did throughout\n",
    "this chapter), Keras automatically converts your function into a TF Function, no need\n",
    "to use tf.function()** . So most of the time, all this magic is 100% transparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell Keras not to convert your Python functions to TF\n",
    "Functions by setting dynamic=True when creating a custom layer\n",
    "or a custom model. Alternatively, you can set run_eagerly=True\n",
    "when calling the model’s compile() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Function generates a new graph for every unique set of input shapes and data\n",
    "types, and it caches it for subsequent calls. For example, if you call tf_cube(tf.constant(10)) , a graph will be generated for int32 tensors of shape []. \n",
    "Then if you call tf_cube(tf.constant(20)) , the same graph will be reused. \n",
    "But if you then call\n",
    "tf_cube(tf.constant([10, 20])) , a new graph will be generated for int32 tensors\n",
    "of shape [2]. This is how TF Functions handle polymorphism (i.e., varying argument\n",
    "types and shapes). However, **this is only true for tensor arguments:** \n",
    "if you pass numerical Python values to a TF Function, a new graph will be generated for every distinct\n",
    "value: for example, calling tf_cube(10) and tf_cube(20) will generate two graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you call a TF Function many times with different numerical\n",
    "Python values, then many graphs will be generated, slowing down\n",
    "your program and using up a lot of RAM. Python values should be\n",
    "reserved for arguments that will have few unique values, such as\n",
    "hyperparameters like the number of neurons per layer. This allows\n",
    "TensorFlow to better optimize each variant of your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the generated function’s source code, you can call ```tf.autograph.to_code(tf_cube.python_function)``` . The code is not\n",
    "meant to be pretty, but it can sometimes help for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def tf__tf_cube(x):\\n  do_return = False\\n  retval_ = ag__.UndefinedReturnValue()\\n  do_return = True\\n  retval_ = x ** 3\\n  cond = ag__.is_undefined_return(retval_)\\n\\n  def get_state():\\n    return ()\\n\\n  def set_state(_):\\n    pass\\n\\n  def if_true():\\n    retval_ = None\\n    return retval_\\n\\n  def if_false():\\n    return retval_\\n  retval_ = ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\\n  return retval_\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.autograph.to_code(tf_cube.python_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call any external library, including NumPy or even the standard library,\n",
    "this call will run only during tracing, it will not be part of the graph. Indeed, a\n",
    "TensorFlow graph can only include TensorFlow constructs (tensors, operations,\n",
    "variables, datasets, and so on). So make sure you use tf.reduce_sum() instead of\n",
    "np.sum() , and tf.sort() instead of the built-in sorted() function, and so on\n",
    "(unless you really want the code to run only during tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
